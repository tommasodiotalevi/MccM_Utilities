{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XToYHTo2B2Z Run3 production  -> Z(llqq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia_fragment_CP5 = \"\"\"\n",
    "from Configuration.Generator.Pythia8CommonSettings_cfi import *\n",
    "from Configuration.Generator.MCTunesRun3ECM13p6TeV.PythiaCP5Settings_cfi import *\n",
    "from Configuration.Generator.PSweightsPythia.PythiaPSweightsSettings_cfi import *\n",
    "\n",
    "generator = cms.EDFilter(\"Pythia8ConcurrentHadronizerFilter\",\n",
    "    maxEventsToPrint = cms.untracked.int32(1),\n",
    "    pythiaPylistVerbosity = cms.untracked.int32(1),\n",
    "    filterEfficiency = cms.untracked.double(1.0),\n",
    "    pythiaHepMCVerbosity = cms.untracked.bool(False),\n",
    "    comEnergy = cms.double(13600.),\n",
    "    PythiaParameters = cms.PSet(\n",
    "        pythia8CommonSettingsBlock,\n",
    "        pythia8CP5SettingsBlock,\n",
    "        pythia8PSweightsSettingsBlock,\n",
    "        processParameters = cms.vstring(\n",
    "        __CHANNEL_DECAY_FRAGMENT__\n",
    "          ),\n",
    "        parameterSets = cms.vstring('pythia8CommonSettings',\n",
    "                                    'pythia8CP5Settings',\n",
    "                                    'pythia8PSweightsSettings',\n",
    "                                    'processParameters')\n",
    "    )\n",
    ")\n",
    "\n",
    "ProductionFilterSequence = cms.Sequence(generator)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragmentsDictCreator (decay_fr):\n",
    "    dict = { #'2023': pythia_fragment_CP5.replace('__CHANNEL_DECAY_FRAGMENT__',decay_fr),\n",
    "             #'2023BPix': pythia_fragment_CP5.replace('__CHANNEL_DECAY_FRAGMENT__',decay_fr),\n",
    "             '2024': pythia_fragment_CP5.replace('__CHANNEL_DECAY_FRAGMENT__',decay_fr),\n",
    "                    }\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHEproducer = \"\"\"\n",
    "import FWCore.ParameterSet.Config as cms\n",
    "\n",
    "# link to cards:\n",
    "# __EXAMPLE__\n",
    "\n",
    "externalLHEProducer = cms.EDProducer('ExternalLHEProducer',\n",
    "    args = cms.vstring('__GRIDPACK__'),\n",
    "    nEvents = cms.untracked.uint32(5000),\n",
    "    numberOfParameters = cms.uint32(1),\n",
    "    outputFile = cms.string('cmsgrid_final.lhe'),\n",
    "    generateConcurrently = cms.untracked.bool(False),\n",
    "    scriptName = cms.FileInPath('GeneratorInterface/LHEInterface/data/run_generic_tarball_cvmfs.sh')\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\"2024\"]#, \"2023\", \"2023BPix\"]\n",
    "mX = [300, 400, 500, 550, 600, 650, 700, 800, 900, 1000, 1200, 1400, 1600, 1800, 2000, 2500, 3000, 3500, 4000]\n",
    "mY = [200, 300, 400, 500, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2600, 3000, 3500]\n",
    "\n",
    "tot_events1 = [100000]*len(mY)\n",
    "gridpacks_dict = {}\n",
    "example_dict = {}\n",
    "dataset_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(len(years)):\n",
    "    t_example1 = 'https://github.com/cms-sw/genproductions/tree/master/bin/MadGraph5_aMCatNLO/cards/production/13p6TeV/NMSSM_XToYH'\n",
    "    t_datasetname_year = 'NMSSM-XtoYHto2Z2Bto2L2J2B_Par-MX-{massX}-MY-{massY}_TuneCP5_13p6TeV_madgraph-pythia8'\n",
    "    t_gp_year = \"/cvmfs/cms.cern.ch/phys_generator/gridpacks/RunIII/13p6TeV/slc7_amd64_gcc10/MadGraph5_aMCatNLO/NMSSM_XYH/NMSSM_XToYH_MX_{massX}_MY_{massY}_slc7_amd64_gcc10_CMSSW_12_4_8_tarball.tar.xz\"    \n",
    "    tmp_dataset_dict={}\n",
    "    tmp_gridpack_dict={}\n",
    "    tmp_example_dict={}\n",
    "    dataset_names_year = []\n",
    "    gp_ggf_year = \"gp_ggf_\" + years[year]\n",
    "    gp_ggf_year = []\n",
    "    \n",
    "    dataset_names_year = []\n",
    "    gp_ggf_year = []\n",
    "\n",
    "    for mx in mX:\n",
    "        for my in mY:\n",
    "            d = {\"massX\": mx, \"massY\": my}\n",
    "            tmp_example_dict = t_example1\n",
    "            gp_ggf_year.append(t_gp_year.format_map(d))\n",
    "            dataset_names_year.append(t_datasetname_year.format_map(d))\n",
    "            tmp_dataset_dict = dataset_names_year\n",
    "            tmp_gridpack_dict = gp_ggf_year\n",
    "        \n",
    "    gridpacks_dict[years[year]] = tmp_gridpack_dict\n",
    "    dataset_names[years[year]] = tmp_dataset_dict\n",
    "    example_dict[years[year]] = tmp_example_dict              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hy_bbgg = '''                                                                                                                                                                                           \n",
    "    '15:onMode = off',\n",
    "    '15:onIfAny = 11 13', # only leptonic tau decays\n",
    "    '23:mMin = 0.05',\n",
    "    '23:onMode = off',\n",
    "    '23:onIfAny = 1 2 3 4 5 11 13 15', # Z->jets decay and a leptonic charged Z decay, including taus\n",
    "    '35:onMode = off',\n",
    "    '35:oneChannel = 1 1 100 23 23',  # Y->ZZ\n",
    "    '35:onIfMatch = 23 23',\n",
    "    '24:mMin = 0.05',\n",
    "    '24:onMode = off',\n",
    "    '25:m0 = 125.0',\n",
    "    '25:onMode = off',\n",
    "    '25:oneChannel = 1 1 100 5 -5', # H->bb\n",
    "    '25:onIfMatch = 5 -5',\n",
    "    'ResonanceDecayFilter:filter = on',\n",
    "    'ResonanceDecayFilter:exclusive = on', #off: require at least the specified number of daughters, on: require exactly the specified number of daughters\n",
    "    'ResonanceDecayFilter:eMuAsEquivalent = off', #on: treat electrons and muons as equivalent\n",
    "    'ResonanceDecayFilter:eMuTauAsEquivalent = on', #on: treat electrons, muons , and taus as equivalent\n",
    "    'ResonanceDecayFilter:allNuAsEquivalent  = off', #on: treat all three neutrino flavours as equivalent\n",
    "    'ResonanceDecayFilter:udscAsEquivalent   = off', #on: treat udsc quarks as equivalent\n",
    "    'ResonanceDecayFilter:udscbAsEquivalent  = on',  #on: treat udscb quarks as equivalent\n",
    "    'ResonanceDecayFilter:mothers = 35,25,23', #list of mothers not specified -> count all particles in hard process+resonance decays (better to avoid specifying mothers when including leptons from the lhe in counting, since intermediate resonances are not gauranteed to appear in general\n",
    "    'ResonanceDecayFilter:daughters = 5,5,23,23,1,1,11,11',\n",
    "    'TauDecays:externalMode=2',\n",
    "'''\n",
    "#'SpaceShower:dipoleRecoil = on' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .csv Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MadgraphVersion = re.compile(\"V5_2\\.[0-9]\\.[0-9]\")\n",
    "process_pythia_map = {}\n",
    "tmp_process_pythia_map = {}\n",
    "tmp_process_pythia_map = fragmentsDictCreator(x_hy_bbgg)\n",
    "process_pythia_map.update(tmp_process_pythia_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for year in range(len(years)):\n",
    "for year in gridpacks_dict:\n",
    "    #print(year)\n",
    "    with open('XtoYHto2B2ZTo2L2J' + '_' + year +'.csv', 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',',\n",
    "                        quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csvwriter.writerow(['Dataset name','Events', 'fragment','notes','Generator','mcdbid','mcm tag','time','size'])\n",
    "        '''if year == \"2016\":\n",
    "                if process == \"Radion\":\n",
    "                    pr = 1606\n",
    "                elif process == \"BulkGraviton\":\n",
    "                    pr = 1631\n",
    "            if year == \"2016APV\":\n",
    "                if process == \"Radion\":\n",
    "                    pr = 812\n",
    "                elif process == \"BulkGraviton\":\n",
    "                    pr = 837\n",
    "            if year == \"2017\":\n",
    "                if process == \"Radion\":\n",
    "                    pr = 1574\n",
    "                elif process == \"BulkGraviton\":\n",
    "                    pr = 1599\n",
    "            if year == \"2018\":\n",
    "                if process == \"Radion\":\n",
    "                    pr = 1612\n",
    "                elif process == \"BulkGraviton\":\n",
    "                    pr = 1637'''\n",
    "        k=0\n",
    "        for i in range(len(mX)):\n",
    "            for j in range(len(mY)):\n",
    "                tmp_fragment=\"\"\n",
    "                #print(gridpacks_dict[year][i])\n",
    "                #print(dataset_names[year][i])\n",
    "                #version = MadgraphVersion.search(path).group(0)\n",
    "                version=\"2.9.13\"\n",
    "                dataset_name = dataset_names[year][k]\n",
    "                if year == \"2023\":\n",
    "                    events = round(tot_events1[j]*0.67)\n",
    "                    #prepid = 'B2G-RunIISummer20UL16wmLHEGENAPV-00' + str(pr)\n",
    "                elif year == \"2023BPix\":\n",
    "                    events = round(tot_events1[j]*0.33)\n",
    "                    #prepid = 'B2G-RunIISummer20UL16wmLHEGEN-0' + str(pr)\n",
    "                elif year == \"2024\":\n",
    "                    events = tot_events1[j]\n",
    "                    tag = \"20260128_todiotal_XtoYHto2Z2Bto2L2J2B_RunIII2024Summer24\"\n",
    "                    \n",
    "                tmp_fragment = LHEproducer.replace('__GRIDPACK__',gridpacks_dict[year][k]) + '\\n' + process_pythia_map[year]\n",
    "                final_fragment = tmp_fragment.replace('__EXAMPLE__',example_dict[year])\n",
    "                note = dataset_name.replace('_',' ')\n",
    "                generators=\"Madgraph_\" + version + \"  Pythia8\"\n",
    "                mcdb_id = '0'\n",
    "                if (mX[i] < 1800): \n",
    "                    time = '25'\n",
    "                elif (mX[i] >= 1800) and (mX[i] < 4000):\n",
    "                    time = '38'\n",
    "                else:\n",
    "                    time = '45'\n",
    "                size = '1400'\n",
    "                if int(mX[i]) > (int(mY[j]) + 125):\n",
    "                    csvwriter.writerow([dataset_name, events, final_fragment, note, generators, mcdb_id, tag, time, size])\n",
    "                #pr = pr+1   \n",
    "                k=k+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
